import sys
from network_security.cloud.s3_syncer import S3Sync
from network_security.components.data_transformation import DataTransformation
from network_security.components.data_validation import DataValidation
from network_security.components.model_trainer import ModelTrainer
from network_security.constants.training_pipeline import TRAINING_BUCKET_NAME
from network_security.entity.artifact_entity import (
    DataIngestionArtifact,
    DataTransformationArtifact,
    DataValidationArtifact,
    ModelTrainerArtifact,
)
from network_security.logging.logger import logging
from network_security.components.data_ingestion import DataIngestion
from network_security.entity.config_entity import (
    DataIngestionConfig,
    DataTransformationConfig,
    DataValidationConfig,
    ModelTrainerConfig,
    TrainingPipelineConfig,
)
from network_security.exception.exception import NetworkSecurityException


class TrainingPipeline:
    def __init__(self):
        self.training_pipeline_config = TrainingPipelineConfig()
        self.s3sync = S3Sync()

    def start_data_ingestion(self) -> DataIngestionArtifact:
        """
        Initiates the data ingestion process for the training pipeline.

        This method configures and starts the data ingestion process, which involves fetching data from various sources,
        cleaning, transforming, and preparing it for further processing in the pipeline. It logs the start and completion
        of the data ingestion process and returns the artifact generated during this process.

        Returns:
            data_ingestion_artifact (DataIngestionArtifact): The artifact generated by the data ingestion process.
        """

        try:
            self.data_ingestion_config = DataIngestionConfig(
                training_pipeline_config=self.training_pipeline_config,
            )
            logging.info("Started Data Ingestion")
            data_ingestion = DataIngestion(
                data_ingestion_config=self.data_ingestion_config,
            )
            data_ingestion_artifact = data_ingestion.initiate_data_ingestion()
            logging.info(
                f"Data Ingestion completed with the artifact: {data_ingestion_artifact}"
            )
            return data_ingestion_artifact

        except Exception as e:
            raise NetworkSecurityException(e, sys)

    def start_data_validation(
        self, data_ingestion_artifact: DataIngestionArtifact
    ) -> DataValidationArtifact:
        """
        Initiates the data validation process for the training pipeline.

        This method configures and starts the data validation process, which involves checking the quality and integrity of the data
        ingested in the previous step. It logs the start and completion of the data validation process and returns the artifact
        generated during this process.

        Parameters:
            data_ingestion_artifact (DataIngestionArtifact): The artifact generated by the data ingestion process.

        Returns:
            data_validation_artifact (DataValidationArtifact): The artifact generated by the data validation process.
        """
        try:
            data_validation_config = DataValidationConfig(
                training_pipeline_config=self.training_pipeline_config
            )
            logging.info("Started Data Validation")
            data_validation = DataValidation(
                data_ingestion_artifact=data_ingestion_artifact,
                data_validation_config=data_validation_config,
            )
            data_validation_artifact = data_validation.initiate_data_validation()
            logging.info(
                "Data Validation completed with the artifact: {data_validation_artifact}"
            )

            return data_validation_artifact
        except Exception as e:
            raise NetworkSecurityException(e, sys)

    def start_data_transformation(
        self, data_validation_artifact: DataValidationArtifact
    ) -> DataTransformationArtifact:
        """
        Initiates the data transformation process for the training pipeline.

        This method configures and starts the data transformation process, which involves transforming the validated data
        into a format suitable for model training. It logs the start and completion of the data transformation process and
        returns the artifact generated during this process.

        Parameters:
            data_validation_artifact (DataValidationArtifact): The artifact generated by the data validation process.

        Returns:
            data_transformation_artifact (DataTransformationArtifact): The artifact generated by the data transformation process.
        """
        try:
            data_transformation_config = DataTransformationConfig(
                training_pipeline_config=self.training_pipeline_config
            )
            logging.info("Started Data Transformation")
            data_transformation = DataTransformation(
                data_transformation_config=data_transformation_config,
                data_validation_artifact=data_validation_artifact,
            )
            data_transformation_artifact = (
                data_transformation.initiate_data_transformation()
            )

            logging.info(
                "Data Transformation completed with the artifact: {data_transformation_artifact}"
            )

            return data_transformation_artifact

        except Exception as e:
            raise NetworkSecurityException(e, sys)

    def start_model_trainer(
        self,
        data_transformation_artifact: DataTransformationArtifact,
    ) -> ModelTrainerArtifact:
        """
        Initiates the model trainer process for the training pipeline.

        This method configures and starts the model trainer process, which involves training a machine learning model
        using the transformed data. It logs the start and completion of the model trainer process and returns the artifact
        generated during this process.

        Parameters:
            data_transformation_artifact (DataTransformationArtifact): The artifact generated by the data transformation process.

        Returns:
            model_trainer_artifact (ModelTrainerArtifact): The artifact generated by the model trainer process.
        """
        try:
            model_trainer_config = ModelTrainerConfig(
                training_pipeline_config=self.training_pipeline_config
            )
            logging.info("Started Model Trainer")
            model_trainer = ModelTrainer(
                model_trainer_config=model_trainer_config,
                data_transformation_artifact=data_transformation_artifact,
            )
            model_trainer_artifact = model_trainer.initiate_model_trainer()
            logging.info(
                "Model Trainer completed with the artifact: {model_trainer_artifact}"
            )
            return model_trainer_artifact

        except Exception as e:
            raise NetworkSecurityException(e, sys)

    def sync_artifact_dir_to_s3(self):
        """
        Syncs the artifact directory to an S3 bucket.

        This method synchronizes the artifact directory generated during the training pipeline
        process to a specified S3 bucket. It constructs the S3 bucket URL based on the training pipeline
        configuration and uses the S3Sync utility to perform the synchronization.
        """
        try:
            aws_bucket_url = f"s3://{TRAINING_BUCKET_NAME}/artifact/{self.training_pipeline_config.timestamp}"
            self.s3sync.sync_folder_to_s3(
                folder=self.training_pipeline_config.artifact_dir,
                aws_bucket_url=aws_bucket_url,
            )
        except Exception as e:
            raise NetworkSecurityException(e, sys)

    def sync_saved_model_dir_to_s3(self):
        """
        Syncs the saved model directory to an S3 bucket.

        This method synchronizes the saved model directory generated during the model training process
        to a specified S3 bucket. It constructs the S3 bucket URL based on the training pipeline
        configuration and uses the S3Sync utility to perform the synchronization.
        """
        try:
            aws_bucket_url = f"s3://{TRAINING_BUCKET_NAME}/final_model/{self.training_pipeline_config.timestamp}"
            self.s3sync.sync_folder_to_s3(
                folder=self.training_pipeline_config.model_dir,
                aws_bucket_url=aws_bucket_url,
            )
        except Exception as e:
            raise NetworkSecurityException(e, sys)

    def run_pipeline(self):
        """
        Executes the entire training pipeline process.

        This method orchestrates the entire training pipeline process,
        starting from data ingestion to model training and finally syncing the artifacts to an S3 bucket.
        It logs the progress of each step and raises an exception if any step fails.
        """
        try:
            data_ingestion_artifact = self.start_data_ingestion()
            data_validation_artifact = self.start_data_validation(
                data_ingestion_artifact
            )
            data_transformation_artifact = self.start_data_transformation(
                data_validation_artifact
            )
            model_trainer_artifact = self.start_model_trainer(
                data_transformation_artifact
            )

            self.sync_artifact_dir_to_s3()
            self.sync_saved_model_dir_to_s3()

            return model_trainer_artifact
        except Exception as e:
            raise NetworkSecurityException(e, sys)
